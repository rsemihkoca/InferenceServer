server:
  host: '0.0.0.0'
  port: 50051

model:
  path: 'yolov10x.pt'
  confidence_threshold: 0.1
  input_size: [640, 640]
  nms_threshold: 0.4

logging:
  level: 'INFO'
  file: 'inference_server.log'

metrics:
  enabled: true
  port: 8000