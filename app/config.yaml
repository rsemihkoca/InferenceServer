model:
  path: "path/to/yolov10x.pt"
  input_size: [640, 640]
  confidence_threshold: 0.5
  nms_threshold: 0.4

server:
  http_port: 8000
  grpc_port: 50051

gpu:
  device_id: 0

logging:
  level: INFO
  file: "inference_server.log"

metrics:
  enabled: true
  port: 8001