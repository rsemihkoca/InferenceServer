server:
  host: "0.0.0.0"
  port: 50051
  version: "1.0.0"

model:
  path: "yolov8n.pt"
  confidence_threshold: 0.1
  nms_threshold: 0.5

logging:
  level: "INFO"
  file: "inference_server.log"

metrics:
  enabled: true
  port: 8000